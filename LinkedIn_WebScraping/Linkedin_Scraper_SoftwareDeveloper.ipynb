{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58b7c5d-3d28-4191-a8e9-afeae07bc990",
   "metadata": {},
   "source": [
    "# Scrape LinkedIn Using Selenium, Request and Beautiful Soup in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d968b2-f09e-4df6-924c-4e604c2cac9a",
   "metadata": {},
   "source": [
    "We are going to scrape Linkedin Jobs. More specifically, the following details will be scraped:\n",
    "- Job Id\n",
    "- Job title\n",
    "- Seniority Level\n",
    "- Location\n",
    "- Job description\n",
    "- number of candidats\n",
    "- posted time ago\n",
    "\n",
    "1. To scrape Job Ids, we will use `selenium` to navigate to this URL: `https://www.linkedin.com/jobs/search?`.\n",
    "\n",
    "`chromedriver` executable and your LinkedIn credentials are required here.\n",
    "\n",
    "3. As explained [here](https://www.scrapingdog.com/blog/scrape-linkedin-jobs/), to scrape other details (level, description...), we will use a simple GET request (leveraging the `requests` library) to this URL: `https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/xxxxxx` where xxxxxx is the job ID.\\\n",
    "This is easier than using clicks from `selenium`.\n",
    "\n",
    "Note that I tried to scrape Job IDs using the guest URL `https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?` but the results were imprecise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b212a74-160b-43d2-b109-e1ffb83f1818",
   "metadata": {},
   "source": [
    "# I-Scraping Linkedin Jobs IDs using selenium and BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2618dbb1-7afd-4cb7-9343-7a709fa0f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium \n",
    "# pip install beautifulsoup4\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import requests\n",
    "\n",
    "import time, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, re, sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d21562-d227-4c5b-bd16-093c740036fb",
   "metadata": {},
   "source": [
    "## Login to Linkedin using selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d4139a-49c9-4e01-822e-bad65b123305",
   "metadata": {},
   "source": [
    "ğŸ”‘ **Note:**\n",
    "\n",
    "1. To use `selenium`, we need a web driver. For instance, the `chromedriver` can be downloaded from [here](https://chromedriver.chromium.org/downloads).\\\n",
    "   Next, we add the chromedriver to the project directory.\n",
    "\n",
    "3. Linkedin credentials (email address and password) are also required. You can save them here: `../data/user_credentials.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "283a8218-3229-418f-8239-46dcf7b5fb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bt4222project@gmail.com', 'bt4222project')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get User Credentials\n",
    "with open('/Users/Jason/Desktop/is3107/is3107_DataEngineering/user_credentials.txt', 'r',encoding=\"utf-8\") as file:\n",
    "    user_credentials = file.readlines()\n",
    "    user_credentials = [line.rstrip() for line in user_credentials]\n",
    "    \n",
    "my_email,my_pwd = user_credentials[0],user_credentials[1]\n",
    "my_email,my_pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ab1d333e-a704-4b40-be5a-e573e16a4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instanciate the chrome service\n",
    "chromedriver_path = \"C:/Users/Jason/Desktop/IS3107/chromedriver.exe\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "\n",
    "# 2. Instanciate the webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(options=options, service=service)\n",
    "\n",
    "# 3. Open the LinkedIn login page\n",
    "driver.get('https://www.linkedin.com/login')\n",
    "time.sleep(10) # waiting for the page to load\n",
    "\n",
    "# 4. Enter email address & password\n",
    "email_input = driver.find_element(By.ID, 'username')\n",
    "password_input = driver.find_element(By.ID, 'password')\n",
    "email_input.send_keys(my_email)\n",
    "password_input.send_keys(my_pwd)\n",
    "\n",
    "# 5. Click the login button\n",
    "password_input.send_keys(Keys.ENTER)\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce703cef-b5d7-430d-9d47-c9b2a84587b3",
   "metadata": {},
   "source": [
    "We will be logged into LinkedIn after running the above code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba38bd7-5d4a-451e-9989-c31a924247fa",
   "metadata": {},
   "source": [
    "## Scraping Linkedin Jobs IDs\n",
    "\n",
    "1. Set the search query parameters: keywords (ie. Job title) and location;\n",
    "2. Search results are displayed on many pages: `25` jobs are listed on each page;\n",
    "3. We will navigate to every page using the `start` parameter (0,25,50...);\n",
    "4. We need to scroll to the bottom of the page to load the full data;\n",
    "5. To get Job Ids, we will parse the HTML content of the page using BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2940fc82-b529-43a0-acbf-f967935e37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Job_IDs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "45f8f663-3dbc-4b90-a8db-e084ddb89921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function 'Scroll to the bottom'. \n",
    "\n",
    "# time.sleep() function is used to provide extra time for the webpage to load. \n",
    "# I used 120 seconds. If the 25 jobs have not loaded during this period, we can make adjust it and test again.\n",
    "\n",
    "def scroll_to_bottom(driver,sleep_time=120):\n",
    "    last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    while True:\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    \n",
    "    time.sleep(sleep_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba66ae2e-6aa7-4ac8-a002-16f3236a34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the first page (start=0) and scroll to the bottom of the page\n",
    "\n",
    "keywords = 'software%20engineer'\n",
    "location = 'singapore'\n",
    "start = 0\n",
    "\n",
    "url = f'https://www.linkedin.com/jobs/search/?keywords={keywords}&location={location}&start={start}'\n",
    "url = requests.utils.requote_uri(url)\n",
    "driver.get(url)\n",
    "scroll_to_bottom(driver,sleep_time=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4721bbff-4d51-4444-af37-92b243c37890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_jobs: 0\n",
      "number_of_pages: 0\n"
     ]
    }
   ],
   "source": [
    "# Get number of jobs found and number of pages:\n",
    "\n",
    "# Parse the HTML content of the page using BeautifulSoup.\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "try:\n",
    "    div_number_of_jobs = soup.find(\"div\",{\"class\":\"jobs-search-results-list__subtitle\"})\n",
    "    number_of_jobs = int(div_number_of_jobs.find('span').get_text().strip().split()[0])\n",
    "except:\n",
    "    number_of_jobs = 0\n",
    "    \n",
    "number_of_pages=math.ceil(number_of_jobs/25)\n",
    "print(\"number_of_jobs:\",number_of_jobs)\n",
    "print(\"number_of_pages:\",number_of_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a990a0c-2cd9-4321-9b5e-43f909e97399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Job Ids present on the first page.\n",
    "\n",
    "def find_Job_Ids(soup):\n",
    "\n",
    "    Job_Ids_on_the_page = []\n",
    "    \n",
    "    job_postings = soup.find_all('li', {'class': 'jobs-search-results__list-item'})\n",
    "    for job_posting in job_postings:\n",
    "        Job_ID = job_posting.get('data-occludable-job-id')\n",
    "        Job_Ids_on_the_page.append(Job_ID)\n",
    "        # job_title = job_posting.find('a', class_='job-card-list__title').get_text().strip()\n",
    "        # location = job_posting.find('li', class_='job-card-container__metadata-item').get_text().strip()\n",
    "    \n",
    "    return Job_Ids_on_the_page    \n",
    "\n",
    "Jobs_on_this_page = find_Job_Ids(soup)\n",
    "List_Job_IDs.extend(Jobs_on_this_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92700a0-ba39-4c40-aa7c-567c0c7e7886",
   "metadata": {},
   "source": [
    "Now that we've scraped the job IDs and number of results from the first page, let's iterate over the remaining pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e294f1b6-af94-4b96-8e12-698304673a71",
   "metadata": {},
   "source": [
    "### Iterate over the remaining pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f753a25-fcce-403f-8cca-366fdc197406",
   "metadata": {},
   "outputs": [],
   "source": [
    "if number_of_pages>1:\n",
    "    \n",
    "    for page_num in range(1,number_of_pages):\n",
    "        print(f\"Scraping page: {page_num}\",end=\"...\")\n",
    "        \n",
    "        # Navigate to page\n",
    "        url = f'https://www.linkedin.com/jobs/search/?keywords={keywords}&location={location}&start={25 * page_num}'\n",
    "        url = requests.utils.requote_uri(url)\n",
    "        driver.get(url)\n",
    "        scroll_to_bottom(driver)\n",
    "\n",
    "        # Parse the HTML content of the page using BeautifulSoup.\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # Get Job Ids present on the page.\n",
    "        Jobs_on_this_page = find_Job_Ids(soup)\n",
    "        List_Job_IDs.extend(Jobs_on_this_page)  \n",
    "        print(f'Jobs found:{len(Jobs_on_this_page)}')\n",
    "\n",
    "pd.DataFrame({\"Job_Id\":List_Job_IDs}).to_csv('Job_Ids.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "632e56da-ef58-4fda-a244-3fe55546f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close the browser and shut down the ChromiumDriver executable that\n",
    "# is started when starting the ChromiumDriver. \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffac401-0e45-46d7-b672-3bc069c9db4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15515da8-558b-4e31-a8a8-2bfbb70f32d8",
   "metadata": {},
   "source": [
    "## Scraping Job description using requests and BeautifulSoup\n",
    "https://www.scrapingdog.com/blog/scrape-linkedin-jobs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5fc78f82-7c4a-42fc-aaf3-bc18a08b4910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "list_job_IDs = pd.read_csv(\"Job_Ids.csv\").Job_Id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5bfbf246-1c5e-403b-b2c2-f40f7a9d49ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3879301587,\n",
       " 3820479502,\n",
       " 3907751399,\n",
       " 3771637074,\n",
       " 3900798064,\n",
       " 3849949342,\n",
       " 3887992941,\n",
       " 3888577120,\n",
       " 3893935374,\n",
       " 3903524965,\n",
       " 3902451922,\n",
       " 3888057008,\n",
       " 3789170493,\n",
       " 3900502509,\n",
       " 3866964302,\n",
       " 3828523024,\n",
       " 3879301571,\n",
       " 3780614897,\n",
       " 3829053920,\n",
       " 3882844672,\n",
       " 3835903406,\n",
       " 3814291603,\n",
       " 3811232439,\n",
       " 3883821374,\n",
       " 3870146673]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_job_IDs = list_job_IDs\n",
    "list_job_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5556de4c-cb2f-450f-9137-354bb3f589f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(html):\n",
    "    '''remove html tags from BeautifulSoup.text'''\n",
    " \n",
    "    # parse html content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    " \n",
    "    for data in soup(['style', 'script']):\n",
    "        # Remove tags\n",
    "        data.decompose()\n",
    " \n",
    "    # return data by retrieving the tag content\n",
    "    return ' '.join(soup.stripped_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51cdbe4a-4213-4e0c-8017-c180e1eb24b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ... read jobId:3879301587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ... read jobId:3820479502\n",
      "3 ... read jobId:3907751399\n",
      "4 ... read jobId:3771637074\n",
      "5 ... read jobId:3900798064\n",
      "6 ... read jobId:3849949342\n",
      "7 ... read jobId:3887992941\n",
      "8 ... read jobId:3888577120\n",
      "9 ... read jobId:3893935374\n",
      "10 ... read jobId:3903524965\n",
      "11 ... read jobId:3902451922\n",
      "12 ... read jobId:3888057008\n",
      "13 ... read jobId:3789170493\n",
      "14 ... read jobId:3900502509\n",
      "15 ... read jobId:3866964302\n",
      "16 ... read jobId:3828523024\n",
      "17 ... read jobId:3879301571\n",
      "18 ... read jobId:3780614897\n",
      "19 ... read jobId:3829053920\n",
      "20 ... read jobId:3882844672\n",
      "21 ... read jobId:3835903406\n",
      "22 ... read jobId:3814291603\n",
      "23 ... read jobId:3811232439\n",
      "24 ... read jobId:3883821374\n",
      "25 ... read jobId:3870146673\n"
     ]
    }
   ],
   "source": [
    "job_url='https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{}'\n",
    "job={}\n",
    "list_jobs=[]\n",
    "\n",
    "for j in range(0,len(list_job_IDs)):\n",
    "    print(f\"{j+1} ... read jobId:{list_job_IDs[j]}\")\n",
    "\n",
    "    resp = requests.get(job_url.format(list_job_IDs[j]))\n",
    "    soup=BeautifulSoup(resp.text,'html.parser')\n",
    "    # print(soup.prettify()) \n",
    "\n",
    "    job[\"Job_ID\"] = list_job_IDs[j] \n",
    "    # try:\n",
    "    #     job[\"Job_html\"] = resp.content\n",
    "    # except:\n",
    "    #     job[\"Job_html\"]=None\n",
    "\n",
    "    try: # remove tags\n",
    "        job[\"Job_txt\"] = remove_tags(resp.content)\n",
    "    except:\n",
    "        job[\"Job_txt\"] = None\n",
    "    \n",
    "    try:\n",
    "        job[\"company\"]=soup.find(\"div\",{\"class\":\"top-card-layout__card\"}).find(\"a\").find(\"img\").get('alt')\n",
    "    except:\n",
    "        job[\"company\"]=None\n",
    "\n",
    "    try:\n",
    "        job[\"job-title\"]=soup.find(\"div\",{\"class\":\"top-card-layout__entity-info\"}).find(\"a\").text.strip()\n",
    "    except:\n",
    "        job[\"job-title\"]=None\n",
    "\n",
    "    try:\n",
    "        job[\"level\"]=soup.find(\"ul\",{\"class\":\"description__job-criteria-list\"}).find(\"li\").text.replace(\"Seniority level\",\"\").strip()\n",
    "    except:\n",
    "        job[\"level\"]=None\n",
    "\n",
    "    try:\n",
    "        job[\"location\"]=soup.find(\"span\",{\"class\":\"topcard__flavor topcard__flavor--bullet\"}).text.strip()\n",
    "    except:\n",
    "        job[\"location\"]=None\n",
    "\n",
    "    try:\n",
    "        job[\"posted-time-ago\"]=soup.find(\"span\",{\"class\":\"posted-time-ago__text topcard__flavor--metadata\"}).text.strip()\n",
    "    except:\n",
    "        job[\"posted-time-ago\"]=None\n",
    "\n",
    "    try:\n",
    "        nb_candidats = soup.find(\"span\",{\"class\":\"num-applicants__caption topcard__flavor--metadata topcard__flavor--bullet\"}).text.strip()\n",
    "        nb_candidats = int(nb_candidats.split()[0])\n",
    "        job[\"nb_candidats\"]= nb_candidats\n",
    "    except:\n",
    "        job[\"nb_candidats\"]=None\n",
    "\n",
    "    list_jobs.append(job)\n",
    "    job={}\n",
    "\n",
    "# create a pandas Datadrame\n",
    "jobs_DF = pd.DataFrame(list_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2bffddba-4bb4-463f-a019-d76c56c21983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_ID</th>\n",
       "      <th>Job_txt</th>\n",
       "      <th>company</th>\n",
       "      <th>job-title</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>posted-time-ago</th>\n",
       "      <th>nb_candidats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3879301587</td>\n",
       "      <td>Full Stack Engineer e2i, Employment &amp; Employab...</td>\n",
       "      <td>e2i, Employment &amp; Employability Institute</td>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>Executive</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3820479502</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3907751399</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3771637074</td>\n",
       "      <td>Software Engineer Intern, Business Infrastruct...</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>Software Engineer Intern, Business Infrastruct...</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3900798064</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Job_ID                                            Job_txt  \\\n",
       "0  3879301587  Full Stack Engineer e2i, Employment & Employab...   \n",
       "1  3820479502                                                      \n",
       "2  3907751399                                                      \n",
       "3  3771637074  Software Engineer Intern, Business Infrastruct...   \n",
       "4  3900798064                                                      \n",
       "\n",
       "                                     company  \\\n",
       "0  e2i, Employment & Employability Institute   \n",
       "1                                       None   \n",
       "2                                       None   \n",
       "3                                     TikTok   \n",
       "4                                       None   \n",
       "\n",
       "                                           job-title           level  \\\n",
       "0                                Full Stack Engineer       Executive   \n",
       "1                                               None            None   \n",
       "2                                               None            None   \n",
       "3  Software Engineer Intern, Business Infrastruct...  Not Applicable   \n",
       "4                                               None            None   \n",
       "\n",
       "               location posted-time-ago  nb_candidats  \n",
       "0  Singapore, Singapore     2 weeks ago         185.0  \n",
       "1                  None            None           NaN  \n",
       "2                  None            None           NaN  \n",
       "3             Singapore    2 months ago         177.0  \n",
       "4                  None            None           NaN  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a199bfad-5d8b-47cb-83e3-4c8553dfc14a",
   "metadata": {},
   "source": [
    "ğŸ”‘ **Note:**\n",
    "\n",
    "Now we have scraped all Linkedin Job details. \n",
    "\n",
    "The next step is to process the data:\n",
    "1. Create a posted_date column using posted_time_ago;\n",
    "2. Clean up 'Job_description' (remove sentences like \"Remove photo First name Last name Email Password ( 8 + characters )\");\n",
    "3. Clean up the 'level' column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb0f88-0ac8-475a-8915-015f2ef18641",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b2c32c38-1c90-4dca-b20a-e6500d64c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_Job_description(text):\n",
    "    senetences_to_remove = [\"Remove photo First name Last name Email Password (8+ characters) \",\n",
    "                            \"By clicking Agree & Join\",\n",
    "                            \"you agree to the LinkedIn User Agreement\",\n",
    "                            \"Privacy Policy and Cookie Policy\",\n",
    "                            \"Continue Agree & Join or Apply on company website\",\n",
    "                            \"Security verification\",\n",
    "                            \"Close Already on LinkedIn ?\",\n",
    "                            \"Close Already on LinkedIn?\",\n",
    "                            \"Sign in Save Save job Save this job with your existing LinkedIn profile , or create a new one\",\n",
    "                            \"Sign in Save Save job Save this job with your existing LinkedIn profile, or create a new one\",\n",
    "                            \"Your job seeking activity is only visible to you\",\n",
    "                            \"Email Continue Welcome back\"]\n",
    "    for sentence in senetences_to_remove:\n",
    "        result = text.find(sentence)\n",
    "        if result>-1:\n",
    "            text = text[:result] + text[result+len(sentence):] # remove sentence from text\n",
    "\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ec0f9a2c-ddd6-428a-82e5-62e3b9d061b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posted_date(posted_time_ago,date_scraping):\n",
    "    \"\"\"Convert posted_time_ago to number of days.\n",
    "    For example, 1 month ago is replaced by 30. 1 week by 7 and so on...\"\"\"\n",
    "    posted_date = None\n",
    "    \n",
    "    try:\n",
    "        details = posted_time_ago.split()\n",
    "        N_DAYS_AGO = int(details[0])\n",
    "        day_week_month_year = details[1] \n",
    "        if day_week_month_year.startswith(\"day\"):\n",
    "            N_DAYS_AGO = N_DAYS_AGO\n",
    "        elif day_week_month_year.startswith(\"week\"):\n",
    "            N_DAYS_AGO = N_DAYS_AGO*7\n",
    "        elif day_week_month_year.startswith(\"month\"):\n",
    "            N_DAYS_AGO = N_DAYS_AGO*30\n",
    "        elif day_week_month_year.startswith(\"year\"):\n",
    "            N_DAYS_AGO = N_DAYS_AGO*365\n",
    "        else:\n",
    "            N_DAYS_AGO = None\n",
    "\n",
    "        posted_date = date_scraping - datetime.timedelta(days=N_DAYS_AGO)\n",
    "    except:\n",
    "        posted_date = None\n",
    "\n",
    "    return posted_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "16261cc5-a680-4d45-8727-596f4b312022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_ID</th>\n",
       "      <th>Job_txt</th>\n",
       "      <th>company</th>\n",
       "      <th>job-title</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>posted-time-ago</th>\n",
       "      <th>nb_candidats</th>\n",
       "      <th>scraping_date</th>\n",
       "      <th>posted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3879301587</td>\n",
       "      <td>Full Stack Engineer e2i, Employment &amp; Employab...</td>\n",
       "      <td>e2i, Employment &amp; Employability Institute</td>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>Executive</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>185.0</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>2024-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3820479502</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3907751399</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3771637074</td>\n",
       "      <td>Software Engineer Intern, Business Infrastruct...</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>Software Engineer Intern, Business Infrastruct...</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>2024-02-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3900798064</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Job_ID                                            Job_txt  \\\n",
       "0  3879301587  Full Stack Engineer e2i, Employment & Employab...   \n",
       "1  3820479502                                                      \n",
       "2  3907751399                                                      \n",
       "3  3771637074  Software Engineer Intern, Business Infrastruct...   \n",
       "4  3900798064                                                      \n",
       "\n",
       "                                     company  \\\n",
       "0  e2i, Employment & Employability Institute   \n",
       "1                                       None   \n",
       "2                                       None   \n",
       "3                                     TikTok   \n",
       "4                                       None   \n",
       "\n",
       "                                           job-title           level  \\\n",
       "0                                Full Stack Engineer       Executive   \n",
       "1                                               None            None   \n",
       "2                                               None            None   \n",
       "3  Software Engineer Intern, Business Infrastruct...  Not Applicable   \n",
       "4                                               None            None   \n",
       "\n",
       "               location posted-time-ago  nb_candidats scraping_date  \\\n",
       "0  Singapore, Singapore     2 weeks ago         185.0    2024-04-22   \n",
       "1                  None            None           NaN    2024-04-22   \n",
       "2                  None            None           NaN    2024-04-22   \n",
       "3             Singapore    2 months ago         177.0    2024-04-22   \n",
       "4                  None            None           NaN    2024-04-22   \n",
       "\n",
       "  posted_date  \n",
       "0  2024-04-08  \n",
       "1         NaT  \n",
       "2         NaT  \n",
       "3  2024-02-22  \n",
       "4         NaT  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_DF['scraping_date'] = pd.to_datetime(datetime.date.today())\n",
    "jobs_DF['posted_date'] = np.vectorize(get_posted_date)(jobs_DF['posted-time-ago'], jobs_DF['scraping_date'])\n",
    "\n",
    "jobs_DF['Job_txt'] = jobs_DF['Job_txt'].apply(clean_Job_description)\n",
    "jobs_DF.level = jobs_DF.level.apply(lambda x:x.replace(\"Employment type\\n        \\n\\n          \",\"\") if x is not None else x)\n",
    "\n",
    "jobs_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3bec7f-929b-4ec6-a1ef-3b5b34018515",
   "metadata": {},
   "source": [
    "## Save to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "45a01750-e57b-45df-95e2-757649ec5707",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_DF.to_json(\"softwareDeveloper_scraped.json\")\n",
    "jobs_DF.to_csv(\"softwareDeveloper_scraped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e47e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_to_bottom(driver,sleep_time=120):\n",
    "    last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    while True:\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    \n",
    "    time.sleep(sleep_time)  \n",
    "    \n",
    "def find_Job_Ids(soup):\n",
    "\n",
    "    Job_Ids_on_the_page = []\n",
    "    \n",
    "    job_postings = soup.find_all('li', {'class': 'jobs-search-results__list-item'})\n",
    "    for job_posting in job_postings:\n",
    "        Job_ID = job_posting.get('data-occludable-job-id')\n",
    "        Job_Ids_on_the_page.append(Job_ID)\n",
    "        # job_title = job_posting.find('a', class_='job-card-list__title').get_text().strip()\n",
    "        # location = job_posting.find('li', class_='job-card-container__metadata-item').get_text().strip()\n",
    "    \n",
    "    return Job_Ids_on_the_page \n",
    "\n",
    "def remove_tags(html):\n",
    "    '''remove html tags from BeautifulSoup.text'''\n",
    " \n",
    "    # parse html content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    " \n",
    "    for data in soup(['style', 'script']):\n",
    "        # Remove tags\n",
    "        data.decompose()\n",
    " \n",
    "    # return data by retrieving the tag content\n",
    "    return ' '.join(soup.stripped_strings)\n",
    "\n",
    "def clean_Job_description(text):\n",
    "    senetences_to_remove = [\"Remove photo First name Last name Email Password (8+ characters) \",\n",
    "                            \"By clicking Agree & Join\",\n",
    "                            \"you agree to the LinkedIn User Agreement\",\n",
    "                            \"Privacy Policy and Cookie Policy\",\n",
    "                            \"Continue Agree & Join or Apply on company website\",\n",
    "                            \"Security verification\",\n",
    "                            \"Close Already on LinkedIn ?\",\n",
    "                            \"Close Already on LinkedIn?\",\n",
    "                            \"Sign in Save Save job Save this job with your existing LinkedIn profile , or create a new one\",\n",
    "                            \"Sign in Save Save job Save this job with your existing LinkedIn profile, or create a new one\",\n",
    "                            \"Your job seeking activity is only visible to you\",\n",
    "                            \"Email Continue Welcome back\"]\n",
    "    for sentence in senetences_to_remove:\n",
    "        result = text.find(sentence)\n",
    "        if result>-1:\n",
    "            text = text[:result] + text[result+len(sentence):] # remove sentence from text\n",
    "\n",
    "    return text \n",
    "\n",
    "def get_posted_date(posted_time_ago,date_scraping):\n",
    "    \"\"\"Convert posted_time_ago to number of days.\n",
    "    For example, 1 month ago is replaced by 30. 1 week by 7 and so on...\"\"\"\n",
    "    posted_date = None\n",
    "    \n",
    "    try:\n",
    "        details = posted_time_ago.split()\n",
    "        N_DAYS_AGO = int(details[0])\n",
    "        day_week_month_year = details[1] \n",
    "        if day_week_month_year.startswith(\"day\"):\n",
    "            N_DAYS_AGO = N_DAYS_AGO\n",
    "        elif day_week_month_year.startswith(\"week\"):\n",
    "            N_DAYS_AGO = N_DAYS_AGO*7\n",
    "        elif day_week_month_year.startswith(\"month\"):\n",
    "            N_DAYS_AGO = N_DAYS_AGO*30\n",
    "        elif day_week_month_year.startswith(\"year\"):\n",
    "            N_DAYS_AGO = N_DAYS_AGO*365\n",
    "        else:\n",
    "            N_DAYS_AGO = None\n",
    "\n",
    "        posted_date = date_scraping - datetime.timedelta(days=N_DAYS_AGO)\n",
    "    except:\n",
    "        posted_date = None\n",
    "\n",
    "    return posted_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cb8354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkedin_scrapper(keyword='AI%20developer', user_credentials_path='/Users/Jason/Desktop/is3107/is3107_DataEngineering/user_credentials.txt', chromedriver_path=\"C:/Users/Jason/Desktop/IS3107/chromedriver.exe\"):\n",
    "    # Get User Credentials\n",
    "    with open(user_credentials_path, 'r',encoding=\"utf-8\") as file:\n",
    "        user_credentials = file.readlines()\n",
    "        user_credentials = [line.rstrip() for line in user_credentials]\n",
    "    my_email,my_pwd = user_credentials[0],user_credentials[1]\n",
    "\n",
    "    # 1. Instanciate the chrome service\n",
    "    chromedriver_path = chromedriver_path\n",
    "    service = Service(executable_path=chromedriver_path)\n",
    "\n",
    "    # 2. Instanciate the webdriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    driver = webdriver.Chrome(options=options, service=service)\n",
    "\n",
    "    # 3. Open the LinkedIn login page\n",
    "    driver.get('https://www.linkedin.com/login')\n",
    "    time.sleep(10) # waiting for the page to load\n",
    "\n",
    "    # 4. Enter email address & password\n",
    "    email_input = driver.find_element(By.ID, 'username')\n",
    "    password_input = driver.find_element(By.ID, 'password')\n",
    "    email_input.send_keys(my_email)\n",
    "    password_input.send_keys(my_pwd)\n",
    "\n",
    "    # 5. Click the login button\n",
    "    password_input.send_keys(Keys.ENTER)\n",
    "    time.sleep(60)\n",
    "\n",
    "    List_Job_IDs = []\n",
    "    keywords = keyword\n",
    "    location = 'singapore'\n",
    "    start = 0\n",
    "    url = f'https://www.linkedin.com/jobs/search/?keywords={keywords}&location={location}&start={start}'\n",
    "    url = requests.utils.requote_uri(url)\n",
    "    driver.get(url)\n",
    "    scroll_to_bottom(driver,sleep_time=10)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    try:\n",
    "        div_number_of_jobs = soup.find(\"div\",{\"class\":\"jobs-search-results-list__subtitle\"})\n",
    "        number_of_jobs = int(div_number_of_jobs.find('span').get_text().strip().split()[0])\n",
    "    except:\n",
    "        number_of_jobs = 0\n",
    "    number_of_pages=math.ceil(number_of_jobs/25)\n",
    "    print(\"number_of_jobs:\",number_of_jobs)\n",
    "    print(\"number_of_pages:\",number_of_pages)\n",
    "\n",
    "    # Get Job Ids present on the first page.\n",
    "    Jobs_on_this_page = find_Job_Ids(soup)\n",
    "    List_Job_IDs.extend(Jobs_on_this_page)\n",
    "\n",
    "    if number_of_pages>1:\n",
    "        for page_num in range(1,number_of_pages):\n",
    "            print(f\"Scraping page: {page_num}\",end=\"...\")\n",
    "            \n",
    "            # Navigate to page\n",
    "            url = f'https://www.linkedin.com/jobs/search/?keywords={keywords}&location={location}&start={25 * page_num}'\n",
    "            url = requests.utils.requote_uri(url)\n",
    "            driver.get(url)\n",
    "            scroll_to_bottom(driver)\n",
    "            \n",
    "            # Parse the HTML content of the page using BeautifulSoup.\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            \n",
    "            # Get Job Ids present on the page.\n",
    "            Jobs_on_this_page = find_Job_Ids(soup)\n",
    "            List_Job_IDs.extend(Jobs_on_this_page)  \n",
    "            print(f'Jobs found:{len(Jobs_on_this_page)}')\n",
    "\n",
    "    ## Close the browser and shut down the ChromiumDriver executable that\n",
    "    # is started when starting the ChromiumDriver. \n",
    "    driver.quit()\n",
    "\n",
    "    job_url='https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{}'\n",
    "    job={}\n",
    "    list_jobs=[]\n",
    "\n",
    "    for j in range(0,len(List_Job_IDs)):\n",
    "        print(f\"{j+1} ... read jobId:{List_Job_IDs[j]}\")\n",
    "\n",
    "        resp = requests.get(job_url.format(List_Job_IDs[j]))\n",
    "        soup=BeautifulSoup(resp.content,'html.parser')\n",
    "\n",
    "        job[\"Job_ID\"] = List_Job_IDs[j]\n",
    "\n",
    "        try:\n",
    "            # apply_link = soup.find(\"a\", {'class':\"jobs-apply-button\"})[\"href\"]\n",
    "            apply_link = 'https://www.linkedin.com/jobs/collections/recommended/?currentJobId={}'.format(List_Job_IDs[j])\n",
    "            # apply_link = job_url.format(List_Job_IDs[j])\n",
    "            job['url'] = apply_link\n",
    "        except:\n",
    "            job['url'] = None\n",
    "\n",
    "        try: # remove tags\n",
    "            job[\"Job_txt\"] = remove_tags(resp.content)\n",
    "            # job[\"Job_txt\"] = soup.find(\"div\", {\"class\":\"description__text description__text--rich\"}).text.strip()\n",
    "        except:\n",
    "            job[\"Job_txt\"] = None\n",
    "            \n",
    "        try:\n",
    "            job[\"company\"]=soup.find(\"div\",{\"class\":\"top-card-layout__card\"}).find(\"a\").find(\"img\").get('alt')\n",
    "        except:\n",
    "            job[\"company\"]=None\n",
    "            \n",
    "        try:\n",
    "            job[\"job-title\"]=soup.find(\"div\",{\"class\":\"top-card-layout__entity-info\"}).find(\"a\").text.strip()\n",
    "        except:\n",
    "            job[\"job-title\"]=None\n",
    "            \n",
    "        try:\n",
    "            job[\"level\"]=soup.find(\"ul\",{\"class\":\"description__job-criteria-list\"}).find(\"li\").text.replace(\"Seniority level\",\"\").strip()\n",
    "        except:\n",
    "            job[\"level\"]=None\n",
    "        \n",
    "        try:\n",
    "            job[\"location\"]=soup.find(\"span\",{\"class\":\"topcard__flavor topcard__flavor--bullet\"}).text.strip()\n",
    "        except:\n",
    "            job[\"location\"]=None\n",
    "            \n",
    "        try:\n",
    "            job[\"posted-time-ago\"]=soup.find(\"span\",{\"class\":\"posted-time-ago__text topcard__flavor--metadata\"}).text.strip()\n",
    "        except:\n",
    "            job[\"posted-time-ago\"]=None\n",
    "            \n",
    "        try:\n",
    "            nb_candidats = soup.find(\"span\",{\"class\":\"num-applicants__caption topcard__flavor--metadata topcard__flavor--bullet\"}).text.strip()\n",
    "            nb_candidats = int(nb_candidats.split()[0])\n",
    "            job[\"nb_candidats\"]= nb_candidats\n",
    "        except:\n",
    "            job[\"nb_candidats\"]=None\n",
    "            \n",
    "        list_jobs.append(job)\n",
    "        job={}   \n",
    "\n",
    "    # create a pandas Datadrame\n",
    "    jobs_DF = pd.DataFrame(list_jobs) \n",
    "\n",
    "    jobs_DF['scraping_date'] = pd.to_datetime(datetime.date.today())\n",
    "    jobs_DF['posted_date'] = np.vectorize(get_posted_date)(jobs_DF['posted-time-ago'], jobs_DF['scraping_date'])\n",
    "\n",
    "    jobs_DF['Job_txt'] = jobs_DF['Job_txt'].apply(clean_Job_description)\n",
    "    jobs_DF.level = jobs_DF.level.apply(lambda x:x.replace(\"Employment type\\n        \\n\\n          \",\"\") if x is not None else x)\n",
    "\n",
    "    jobs_DF.to_json(\"{}_scraped.json\".format(keyword.replace('%20', '')))\n",
    "    jobs_DF.to_csv(\"{}_scraped.csv\".format(keyword.replace('%20', '')))\n",
    "    return jobs_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3a7c655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_jobs: 0\n",
      "number_of_pages: 0\n",
      "1 ... read jobId:3879301587\n",
      "2 ... read jobId:3820479502\n",
      "3 ... read jobId:3876416396\n",
      "4 ... read jobId:3890442134\n",
      "5 ... read jobId:3780614897\n",
      "6 ... read jobId:3771637074\n",
      "7 ... read jobId:3900798064\n",
      "8 ... read jobId:3893119219\n",
      "9 ... read jobId:3843041729\n",
      "10 ... read jobId:3882844672\n",
      "11 ... read jobId:3888577120\n",
      "12 ... read jobId:3879301571\n",
      "13 ... read jobId:3903524965\n",
      "14 ... read jobId:3829053920\n",
      "15 ... read jobId:3900502509\n",
      "16 ... read jobId:3849949342\n",
      "17 ... read jobId:3775187042\n",
      "18 ... read jobId:3688875998\n",
      "19 ... read jobId:3783567440\n",
      "20 ... read jobId:3751241217\n",
      "21 ... read jobId:3888052027\n",
      "22 ... read jobId:3883629706\n",
      "23 ... read jobId:3794624979\n",
      "24 ... read jobId:3814291603\n",
      "25 ... read jobId:3897134160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_ID</th>\n",
       "      <th>url</th>\n",
       "      <th>Job_txt</th>\n",
       "      <th>company</th>\n",
       "      <th>job-title</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>posted-time-ago</th>\n",
       "      <th>nb_candidats</th>\n",
       "      <th>scraping_date</th>\n",
       "      <th>posted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3879301587</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Full Stack Engineer e2i, Employment &amp; Employab...</td>\n",
       "      <td>e2i, Employment &amp; Employability Institute</td>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>Executive</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>3 weeks ago</td>\n",
       "      <td>191.0</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3820479502</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3876416396</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>IT Infrastructure Engineer Resorts World Sento...</td>\n",
       "      <td>Resorts World Sentosa</td>\n",
       "      <td>IT Infrastructure Engineer</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>3 weeks ago</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3890442134</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3780614897</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Senior IT Infrastructure Engineer ONE Singapor...</td>\n",
       "      <td>ONE</td>\n",
       "      <td>Senior IT Infrastructure Engineer</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3771637074</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Software Engineer Intern, Business Infrastruct...</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>Software Engineer Intern, Business Infrastruct...</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3900798064</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Internship - Software Engineer Infineon Techno...</td>\n",
       "      <td>Infineon Technologies</td>\n",
       "      <td>Internship - Software Engineer</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3893119219</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3843041729</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Software Engineer Intern Thales Singapore, Sin...</td>\n",
       "      <td>Thales</td>\n",
       "      <td>Software Engineer Intern</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>1 month ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3882844672</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>IT Systems Engineer Crone Corkill Singapore, S...</td>\n",
       "      <td>Crone Corkill</td>\n",
       "      <td>IT Systems Engineer</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3888577120</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Devops Engineer Singtel Singapore, Singapore 2...</td>\n",
       "      <td>Singtel</td>\n",
       "      <td>Devops Engineer</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3879301571</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3903524965</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Full Stack Software Engineer Intern (6 months)...</td>\n",
       "      <td>Hypotenuse AI</td>\n",
       "      <td>Full Stack Software Engineer Intern (6 months)</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3829053920</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Junior Software Engineer Capgemini Singapore, ...</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>Junior Software Engineer</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>1 month ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3900502509</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Senior System Engineer Beyondsoft Singapore Si...</td>\n",
       "      <td>Beyondsoft Singapore</td>\n",
       "      <td>Senior System Engineer</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>123.0</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3849949342</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3775187042</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>2024 Blackstone Technology and Innovations - S...</td>\n",
       "      <td>Blackstone</td>\n",
       "      <td>2024 Blackstone Technology and Innovations - S...</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3688875998</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Software Engineer Illumina Singapore 1 month a...</td>\n",
       "      <td>Illumina</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1 month ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3783567440</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3751241217</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Software Developer Singtel Singapore, Singapor...</td>\n",
       "      <td>Singtel</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>1 month ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3888052027</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3883629706</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Software Engineer Nicoll Curtin Singapore, Sin...</td>\n",
       "      <td>Nicoll Curtin</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3794624979</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Software Developer GoNetZeroâ„¢ Singapore, Singa...</td>\n",
       "      <td>GoNetZeroâ„¢</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>3 weeks ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3814291603</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Software Engineer (Intern) Thales Singapore, S...</td>\n",
       "      <td>Thales</td>\n",
       "      <td>Software Engineer (Intern)</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3897134160</td>\n",
       "      <td>https://www.linkedin.com/jobs/collections/reco...</td>\n",
       "      <td>Software Developer YSQ International Singapore...</td>\n",
       "      <td>YSQ International</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>2024-04-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Job_ID                                                url  \\\n",
       "0   3879301587  https://www.linkedin.com/jobs/collections/reco...   \n",
       "1   3820479502  https://www.linkedin.com/jobs/collections/reco...   \n",
       "2   3876416396  https://www.linkedin.com/jobs/collections/reco...   \n",
       "3   3890442134  https://www.linkedin.com/jobs/collections/reco...   \n",
       "4   3780614897  https://www.linkedin.com/jobs/collections/reco...   \n",
       "5   3771637074  https://www.linkedin.com/jobs/collections/reco...   \n",
       "6   3900798064  https://www.linkedin.com/jobs/collections/reco...   \n",
       "7   3893119219  https://www.linkedin.com/jobs/collections/reco...   \n",
       "8   3843041729  https://www.linkedin.com/jobs/collections/reco...   \n",
       "9   3882844672  https://www.linkedin.com/jobs/collections/reco...   \n",
       "10  3888577120  https://www.linkedin.com/jobs/collections/reco...   \n",
       "11  3879301571  https://www.linkedin.com/jobs/collections/reco...   \n",
       "12  3903524965  https://www.linkedin.com/jobs/collections/reco...   \n",
       "13  3829053920  https://www.linkedin.com/jobs/collections/reco...   \n",
       "14  3900502509  https://www.linkedin.com/jobs/collections/reco...   \n",
       "15  3849949342  https://www.linkedin.com/jobs/collections/reco...   \n",
       "16  3775187042  https://www.linkedin.com/jobs/collections/reco...   \n",
       "17  3688875998  https://www.linkedin.com/jobs/collections/reco...   \n",
       "18  3783567440  https://www.linkedin.com/jobs/collections/reco...   \n",
       "19  3751241217  https://www.linkedin.com/jobs/collections/reco...   \n",
       "20  3888052027  https://www.linkedin.com/jobs/collections/reco...   \n",
       "21  3883629706  https://www.linkedin.com/jobs/collections/reco...   \n",
       "22  3794624979  https://www.linkedin.com/jobs/collections/reco...   \n",
       "23  3814291603  https://www.linkedin.com/jobs/collections/reco...   \n",
       "24  3897134160  https://www.linkedin.com/jobs/collections/reco...   \n",
       "\n",
       "                                              Job_txt  \\\n",
       "0   Full Stack Engineer e2i, Employment & Employab...   \n",
       "1                                                       \n",
       "2   IT Infrastructure Engineer Resorts World Sento...   \n",
       "3                                                       \n",
       "4   Senior IT Infrastructure Engineer ONE Singapor...   \n",
       "5   Software Engineer Intern, Business Infrastruct...   \n",
       "6   Internship - Software Engineer Infineon Techno...   \n",
       "7                                                       \n",
       "8   Software Engineer Intern Thales Singapore, Sin...   \n",
       "9   IT Systems Engineer Crone Corkill Singapore, S...   \n",
       "10  Devops Engineer Singtel Singapore, Singapore 2...   \n",
       "11                                                      \n",
       "12  Full Stack Software Engineer Intern (6 months)...   \n",
       "13  Junior Software Engineer Capgemini Singapore, ...   \n",
       "14  Senior System Engineer Beyondsoft Singapore Si...   \n",
       "15                                                      \n",
       "16  2024 Blackstone Technology and Innovations - S...   \n",
       "17  Software Engineer Illumina Singapore 1 month a...   \n",
       "18                                                      \n",
       "19  Software Developer Singtel Singapore, Singapor...   \n",
       "20                                                      \n",
       "21  Software Engineer Nicoll Curtin Singapore, Sin...   \n",
       "22  Software Developer GoNetZeroâ„¢ Singapore, Singa...   \n",
       "23  Software Engineer (Intern) Thales Singapore, S...   \n",
       "24  Software Developer YSQ International Singapore...   \n",
       "\n",
       "                                      company  \\\n",
       "0   e2i, Employment & Employability Institute   \n",
       "1                                        None   \n",
       "2                       Resorts World Sentosa   \n",
       "3                                        None   \n",
       "4                                         ONE   \n",
       "5                                      TikTok   \n",
       "6                       Infineon Technologies   \n",
       "7                                        None   \n",
       "8                                      Thales   \n",
       "9                               Crone Corkill   \n",
       "10                                    Singtel   \n",
       "11                                       None   \n",
       "12                              Hypotenuse AI   \n",
       "13                                  Capgemini   \n",
       "14                       Beyondsoft Singapore   \n",
       "15                                       None   \n",
       "16                                 Blackstone   \n",
       "17                                   Illumina   \n",
       "18                                       None   \n",
       "19                                    Singtel   \n",
       "20                                       None   \n",
       "21                              Nicoll Curtin   \n",
       "22                                 GoNetZeroâ„¢   \n",
       "23                                     Thales   \n",
       "24                          YSQ International   \n",
       "\n",
       "                                            job-title             level  \\\n",
       "0                                 Full Stack Engineer         Executive   \n",
       "1                                                None              None   \n",
       "2                          IT Infrastructure Engineer  Mid-Senior level   \n",
       "3                                                None              None   \n",
       "4                   Senior IT Infrastructure Engineer  Mid-Senior level   \n",
       "5   Software Engineer Intern, Business Infrastruct...    Not Applicable   \n",
       "6                      Internship - Software Engineer       Entry level   \n",
       "7                                                None              None   \n",
       "8                            Software Engineer Intern    Not Applicable   \n",
       "9                                 IT Systems Engineer  Mid-Senior level   \n",
       "10                                    Devops Engineer       Entry level   \n",
       "11                                               None              None   \n",
       "12     Full Stack Software Engineer Intern (6 months)        Internship   \n",
       "13                           Junior Software Engineer       Entry level   \n",
       "14                             Senior System Engineer         Associate   \n",
       "15                                               None              None   \n",
       "16  2024 Blackstone Technology and Innovations - S...        Internship   \n",
       "17                                  Software Engineer    Not Applicable   \n",
       "18                                               None              None   \n",
       "19                                 Software Developer       Entry level   \n",
       "20                                               None              None   \n",
       "21                                  Software Engineer  Mid-Senior level   \n",
       "22                                 Software Developer         Associate   \n",
       "23                         Software Engineer (Intern)    Not Applicable   \n",
       "24                                 Software Developer         Associate   \n",
       "\n",
       "                location posted-time-ago  nb_candidats scraping_date  \\\n",
       "0   Singapore, Singapore     3 weeks ago         191.0    2024-04-23   \n",
       "1                   None            None           NaN    2024-04-23   \n",
       "2   Singapore, Singapore     3 weeks ago         199.0    2024-04-23   \n",
       "3                   None            None           NaN    2024-04-23   \n",
       "4   Singapore, Singapore     2 weeks ago           NaN    2024-04-23   \n",
       "5              Singapore    2 months ago         177.0    2024-04-23   \n",
       "6              Singapore      1 week ago         114.0    2024-04-23   \n",
       "7                   None            None           NaN    2024-04-23   \n",
       "8   Singapore, Singapore     1 month ago           NaN    2024-04-23   \n",
       "9   Singapore, Singapore     2 weeks ago           NaN    2024-04-23   \n",
       "10  Singapore, Singapore     2 weeks ago          43.0    2024-04-23   \n",
       "11                  None            None           NaN    2024-04-23   \n",
       "12             Singapore      6 days ago         161.0    2024-04-23   \n",
       "13  Singapore, Singapore     1 month ago           NaN    2024-04-23   \n",
       "14  Singapore, Singapore      6 days ago         123.0    2024-04-23   \n",
       "15                  None            None           NaN    2024-04-23   \n",
       "16             Singapore     2 weeks ago           NaN    2024-04-23   \n",
       "17             Singapore     1 month ago           NaN    2024-04-23   \n",
       "18                  None            None           NaN    2024-04-23   \n",
       "19  Singapore, Singapore     1 month ago           NaN    2024-04-23   \n",
       "20                  None            None           NaN    2024-04-23   \n",
       "21  Singapore, Singapore     2 weeks ago          56.0    2024-04-23   \n",
       "22  Singapore, Singapore     3 weeks ago           NaN    2024-04-23   \n",
       "23  Singapore, Singapore    2 months ago           NaN    2024-04-23   \n",
       "24  Singapore, Singapore      1 week ago           NaN    2024-04-23   \n",
       "\n",
       "   posted_date  \n",
       "0   2024-04-02  \n",
       "1          NaT  \n",
       "2   2024-04-02  \n",
       "3          NaT  \n",
       "4   2024-04-09  \n",
       "5   2024-02-23  \n",
       "6   2024-04-16  \n",
       "7          NaT  \n",
       "8   2024-03-24  \n",
       "9   2024-04-09  \n",
       "10  2024-04-09  \n",
       "11         NaT  \n",
       "12  2024-04-17  \n",
       "13  2024-03-24  \n",
       "14  2024-04-17  \n",
       "15         NaT  \n",
       "16  2024-04-09  \n",
       "17  2024-03-24  \n",
       "18         NaT  \n",
       "19  2024-03-24  \n",
       "20         NaT  \n",
       "21  2024-04-09  \n",
       "22  2024-04-02  \n",
       "23  2024-02-23  \n",
       "24  2024-04-16  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_scrapper('software%20engineer')\n",
    "linkedin_scrapper('data%20analyst')\n",
    "linkedin_scrapper('data%20scientist')\n",
    "linkedin_scrapper('machine%20learning%20engineer')\n",
    "linkedin_scrapper('AI%20developer')\n",
    "linkedin_scrapper('data%20engineer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
